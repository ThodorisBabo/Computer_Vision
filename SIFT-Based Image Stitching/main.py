# -*- coding: utf-8 -*-
"""Test.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1j-ViTxMEuw4OFWY0HgEuvc6zHrv2ojLz
"""

import numpy as np
import cv2 as cv
import matplotlib.pyplot as plt  # For displaying images in Colab

# Function to convert custom matches to OpenCV DMatch format
def convert_to_dmatch(matches):
    converted_matches = [cv.DMatch(i[0], i[1], i[2]) for i in matches]
    return converted_matches

# Function to match descriptors between two images
def match_descriptors(desc1, desc2):
    num_features = desc1.shape[0]
    matches = []

    for i in range(num_features):
        feature_vector = desc1[i, :]
        diff = np.abs(desc2 - feature_vector)
        distances = np.sum(diff, axis=1)

        i2 = np.argmin(distances)
        min_dist2 = distances[i2]

        distances[i2] = np.inf
        i3 = np.argmin(distances)
        min_dist3 = distances[i3]

        if min_dist2 / min_dist3 < 0.5:
            matches.append((i, i2, min_dist2))

    return matches

# Function to perform cross-matching
def cross_match(match1, match2):
    cross_matches = []

    for m1 in match1:
        for m2 in match2:
            if (m1[0] == m2[1]) and (m1[1] == m2[0]) and (m1[2] == m2[2]):
                cross_matches.append(cv.DMatch(m1[0], m1[1], m1[2]))

    return cross_matches

# Function to crop black regions from an image
def crop_image(img):
    rows, cols, _ = img.shape
    max_row, max_col = 0, 0

    for i in range(rows):
        for j in range(cols):
            if img[i][j].sum() != 0:
                max_row = max(max_row, i)
                max_col = max(max_col, j)

    return img[:max_row - 10, :max_col - 10]

# Initialize SIFT detector
sift = cv.SIFT_create(1000)

# Load images
img1 = cv.imread('/content/rio-01.png')
img2 = cv.imread('/content/rio-02.png')
img3 = cv.imread('/content/rio-03.png')
img4 = cv.imread('/content/rio-04.png')

# Detect keypoints and compute descriptors
kp1, desc1 = sift.detectAndCompute(img1, None)
kp2, desc2 = sift.detectAndCompute(img2, None)
kp3, desc3 = sift.detectAndCompute(img3, None)
kp4, desc4 = sift.detectAndCompute(img4, None)

# Match descriptors
matches12 = match_descriptors(desc1, desc2)
matches21 = match_descriptors(desc2, desc1)
matches34 = match_descriptors(desc3, desc4)
matches43 = match_descriptors(desc4, desc3)

# Perform cross-matching
cross_matches12 = cross_match(matches12, matches21)
cross_matches34 = cross_match(matches34, matches43)

# Convert matches to DMatch format
match1_dmatch = convert_to_dmatch(matches12)
match3_dmatch = convert_to_dmatch(matches34)

# Draw matches
img_matches12 = cv.drawMatches(img1, kp1, img2, kp2, match1_dmatch, None)
img_matches34 = cv.drawMatches(img3, kp3, img4, kp4, match3_dmatch, None)
cv.imwrite('dimg1.png', img_matches12)
cv.imwrite('dimg3.png', img_matches34)

# Extract matched keypoints
pts1 = np.array([kp1[m.queryIdx].pt for m in cross_matches12])
pts2 = np.array([kp2[m.trainIdx].pt for m in cross_matches12])
pts3 = np.array([kp3[m.queryIdx].pt for m in cross_matches34])
pts4 = np.array([kp4[m.trainIdx].pt for m in cross_matches34])

# Compute homography and warp images
M12, _ = cv.findHomography(pts2, pts1, cv.RANSAC)
M34, _ = cv.findHomography(pts4, pts3, cv.RANSAC)

img12 = cv.warpPerspective(img2, M12, (img1.shape[1] + 1000, img1.shape[0] + 1000))
img34 = cv.warpPerspective(img4, M34, (img3.shape[1] + 1000, img3.shape[0] + 1000))
img12[:img1.shape[0], :img1.shape[1]] = img1
img34[:img3.shape[0], :img3.shape[1]] = img3

cv.imwrite('12-before.png', img12)
cv.imwrite('34-before.png', img34)

# Crop images
img12 = crop_image(img12)
img34 = crop_image(img34)

# Detect and compute descriptors for combined images
kp12, desc12 = sift.detectAndCompute(img12, None)
kp34, desc34 = sift.detectAndCompute(img34, None)

# Match between img12 and img34
matches_12_34 = match_descriptors(desc12, desc34)
matches_34_12 = match_descriptors(desc34, desc12)
cross_matches_total = cross_match(matches_12_34, matches_34_12)

# Convert matches and draw
match_12_34_dmatch = convert_to_dmatch(matches_12_34)
img_matches_total = cv.drawMatches(img12, kp12, img34, kp34, match_12_34_dmatch, None)
cv.imwrite('dimgtotal.png', img_matches_total)

# Compute homography for final image
pts12 = np.array([kp12[m.queryIdx].pt for m in cross_matches_total])
pts34 = np.array([kp34[m.trainIdx].pt for m in cross_matches_total])
M_total, _ = cv.findHomography(pts34, pts12, cv.RANSAC)

# Warp final image
img_total = cv.warpPerspective(img34, M_total, (img12.shape[1] + 1000, img12.shape[0] + 1000))
img_total[:img12.shape[0], :img12.shape[1]] = img12

cv.imwrite('total-before.png', img_total)

# Crop final image
img_total = crop_image(img_total)

# Save final images
cv.imwrite('12.png', img12)
cv.imwrite('34.png', img34)
cv.imwrite('total.png', img_total)

# Display images using Matplotlib (Google Colab friendly)
def show_image(img, title):
    plt.imshow(cv.cvtColor(img, cv.COLOR_BGR2RGB))
    plt.title(title)
    plt.axis('off')
    plt.show()

show_image(img12, 'Stitched Image 12')
show_image(img34, 'Stitched Image 34')
show_image(img_total, 'Final Stitched Image')